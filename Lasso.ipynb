{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is going to be helpful in question 11 to compute the test error rate\n",
    "#this is counting the amount of values outside a specific range and dividing it over the length of the data\n",
    "def test_error_rate(y_test,prediction):\n",
    "    error = 0\n",
    "    test_error = 0\n",
    "    for index in range(len(y_test)):\n",
    "        if y_test[index] < prediction[index][1] and y_test[index] > prediction[index][0]:\n",
    "            continue\n",
    "        else:\n",
    "            error += 1\n",
    "    return error/ len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) split the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = diabetes.data\n",
    "y = diabetes.target\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y,random_state = 408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) training and testing R squared and the number of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r squared score for training is: 0.36859375515801496\n",
      "the r squared score for testing is: 0.3403312415954568\n",
      "[  0.           0.         347.65886726 127.46177627   0.\n",
      "   0.          -0.           0.         233.92769906   0.        ]\n",
      "the number of features used is: 3\n",
      "the features used in order to predict this dataset are: ['bmi', 'bp', 's5']\n"
     ]
    }
   ],
   "source": [
    "#creating the classifier\n",
    "clf = linear_model.Lasso()\n",
    "\n",
    "#fitting the data ( training the model )\n",
    "clf.fit(X_train,y_train)\n",
    "\n",
    "#predicting on the training and testing sets\n",
    "predict_training =clf.predict(X_train)\n",
    "predict_testing = clf.predict(X_test)\n",
    "\n",
    "#calculating r score for training and testing\n",
    "r2_score_for_training = r2_score(y_train, predict_training)\n",
    "r2_score_for_testing = r2_score(y_test, predict_testing)\n",
    "\n",
    "print(\"the r squared score for training is:\",r2_score_for_training)\n",
    "print(\"the r squared score for testing is:\",r2_score_for_testing)\n",
    "\n",
    "#as we can see this model is using 3 features to predict the model and ignoring the others\n",
    "#when we run this print, it will produce 10 values of which 3 are non-zero so we can see this model uses only 3 features\n",
    "print(clf.coef_)\n",
    "\n",
    "#using clf.coef_ to calculate how many feature are non zero\n",
    "features_used = []\n",
    "for i in range(0,len(clf.coef_)):\n",
    "    if clf.coef_[i] != 0:\n",
    "        features_used.append(diabetes['feature_names'][i])\n",
    "        \n",
    "print(\"the number of features used is:\",len(features_used))\n",
    "print(\"the features used in order to predict this dataset are:\",features_used)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) importing data from the file instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data are saved in a txt file that is why I have used the csv.reader then produce a list out of those data\n",
    "import csv\n",
    "with open('C:/Users/kali/Desktop/Tab-delimited diabetes data.txt') as f:\n",
    "    reader = csv.reader(f, delimiter=\"\\t\")\n",
    "    d = list(reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have divided the data into features, labels and data to predict add the data that i need\n",
    "features = []\n",
    "data = []\n",
    "label = []\n",
    "\n",
    "for i in range(0,len(d)):\n",
    "    array_of_data = []\n",
    "    if i == 0:\n",
    "        features.append(d[i])\n",
    "    else:\n",
    "        for j in range(0,len(d[0])):\n",
    "            if j != len(d[0]) - 1:\n",
    "                array_of_data.append(d[i][j])\n",
    "            else:\n",
    "                label.append(d[i][j])\n",
    "        data.append(array_of_data)        \n",
    "features = np.array(features[0])\n",
    "label = np.array(label)\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) splitting these data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(data,label,random_state=408)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the standardscaler function to Scale the data then fitting them using training set\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaler = scaler.transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)\n",
    "\n",
    "#this is important because the data have different types ( some are int some are float )\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "y_test = y_test.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Repeating 3 with the new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in here the rsquared for both training and testing is higher than the first one and this is due to taking more features into consideration where in the first one the classifier took 3 features to compute the rsquared but in here it took 8 features ( the more features we take the higher the r squared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the r squared score for the new data training is: 0.5219263505249627\n",
      "the r squared score for the new data tresting is: 0.4364337921284196\n",
      "the number of features used is: 8\n",
      "the features used in order to predict this dataset are: ['sex', 'bmi', 'bp', 's1', 's2', 's3', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train,y_train)\n",
    "predicting_new_training = clf.predict(X_train)\n",
    "predicting_new_testing = clf.predict(X_test)\n",
    "new_r2_score_for_training = r2_score(y_train,predicting_new_training)\n",
    "new_r2_score_for_testing = r2_score(y_test,predicting_new_testing)\n",
    "print(\"the r squared score for the new data training is:\",new_r2_score_for_training)\n",
    "print(\"the r squared score for the new data tresting is:\",new_r2_score_for_testing)\n",
    "\n",
    "features_used = []\n",
    "for i in range(0,len(clf.coef_)):\n",
    "    if clf.coef_[i] != 0:\n",
    "        features_used.append(diabetes['feature_names'][i])\n",
    "print(\"the number of features used is:\",len(features_used))\n",
    "print(\"the features used in order to predict this dataset are:\",features_used)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) preprocess data using StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in here, I have preprocessed the data but I used the variables created before \n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_scaler = scaler.transform(X_train)\n",
    "X_test_scaler = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Repeat the process using the new StandardScaler data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we can see in here, the training and testing r squared are close to the ones in question 6 and not in question 3. we would expect the model to produce similar result to 6 and 3 but the thing is, in here we are taking 1 more feature than question 6 and 5 more than 3, this will result in a bit higher r squared than question 6 which is confirmed and much higher than question 3 which is also confirmed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rsquared for training scalar prediction is: 0.5253295326189974\n",
      "rsquared for testing scalar prediction is: 0.45579992198161157\n",
      "the number of features used is: 7\n",
      "the features used in order to predict this dataset are: ['sex', 'bmi', 'bp', 's1', 's3', 's5', 's6']\n"
     ]
    }
   ],
   "source": [
    "clf.fit(X_train_scaler,y_train)\n",
    "prediction_for_training = clf.predict(X_train_scaler)\n",
    "prediction_for_testing = clf.predict(X_test_scaler)\n",
    "r2_score_for_scaler_training = r2_score(y_train,prediction_for_training)\n",
    "r2_score_for_scaler_testing = r2_score(y_test,prediction_for_testing)\n",
    "print(\"rsquared for training scalar prediction is:\",r2_score_for_scaler_training)\n",
    "print(\"rsquared for testing scalar prediction is:\",r2_score_for_scaler_testing)\n",
    "\n",
    "features_used = []\n",
    "for i in range(0,len(clf.coef_)):\n",
    "    if clf.coef_[i] != 0:\n",
    "        features_used.append(diabetes['feature_names'][i])\n",
    "print(\"the number of features used is:\",len(features_used))\n",
    "print(\"the features used in order to predict this dataset are:\",features_used)        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) varying alpha values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have created this code which will take different values of values and for each one i have trained my new model based on it\n",
    "alpha = list(np.arange(0.01,40,0.01))\n",
    "alpha_used = []\n",
    "number_of_features_used = []\n",
    "r_squared_used = []\n",
    "\n",
    "for i in alpha:\n",
    "    clf = linear_model.Lasso(alpha=i)\n",
    "    clf.fit(X_train_scaler,y_train)\n",
    "    predict_testing = clf.predict(X_test_scaler)\n",
    "    r2 = r2_score(y_test, predict_testing)\n",
    "    alpha_used.append(i)\n",
    "    number_of_features_used.append(np.count_nonzero(clf.coef_))\n",
    "    r_squared_used.append(r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have created a dataframe which will take have later three values the number of features, alpha used for each one and the r squared calculated for it\n",
    "df = pd.DataFrame(columns=['number of features used', 'r squared', 'alpha used'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is used to fit the 3 columns data into the dataframe using .loc\n",
    "for i in range(0,len(alpha_used)):\n",
    "    df.loc[i] = number_of_features_used[i],r_squared_used[i],alpha_used[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i have used grouby and idmax to get the maximum value of rsquared of each feature used and getting the alpha for it \n",
    "df = df.loc[df.groupby('number of features used')['r squared'].idxmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>number of features used</th>\n",
       "      <th>r squared</th>\n",
       "      <th>alpha used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3172</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.210795</td>\n",
       "      <td>31.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.381859</td>\n",
       "      <td>15.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.432062</td>\n",
       "      <td>5.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.447246</td>\n",
       "      <td>3.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.452265</td>\n",
       "      <td>2.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.455851</td>\n",
       "      <td>1.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.455641</td>\n",
       "      <td>0.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.456753</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.458532</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      number of features used  r squared  alpha used\n",
       "3172                      2.0   0.210795       31.73\n",
       "1593                      3.0   0.381859       15.94\n",
       "567                       4.0   0.432062        5.68\n",
       "359                       5.0   0.447246        3.60\n",
       "261                       6.0   0.452265        2.62\n",
       "118                       7.0   0.455851        1.19\n",
       "64                        8.0   0.455641        0.65\n",
       "10                        9.0   0.456753        0.11\n",
       "0                        10.0   0.458532        0.01"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "looking at the graph, i would take 7 features where it gave me 0.455851 rsquared. the reason for this is that there isn't much difference between 7 to 10 features and 6 and 7 are similar with 7 being a bit higher and the remaining have bigger difference so I could take either 6 or 7 since they are similar but since its just a 1 feature difference and bit rsquared difference I'd choose 7 features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x234bd661080>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#for each number of feature, i have plotted the corresponding r squared for it where we can conclude that 7 features is the best\n",
    "df.plot(x=\"number of features used\", y='r squared')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) choosing regularization parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is a list containing different values for alpha just like before\n",
    "alpha_values = list(np.arange(0.1,3,0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will return the cross validation score of the model created for a different alpha value on the training data scaled\n",
    "mean_values = np.empty(len(alpha_values))\n",
    "for i in range(0,len(alpha_values)):\n",
    "    clf = linear_model.Lasso(alpha=alpha_values[i])\n",
    "    clf.fit(X_train_scaler,y_train)\n",
    "    mean_values[i] = np.mean(cross_val_score(clf,X_train_scaler,y_train,cv=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#in here, I have taken the maximum value of the mean values calculated in the previous cell, then the enumerate is serving as a \n",
    "#index calculation to get the index of this maximum value and returning the corresponding alpha chosen\n",
    "max_value = max(mean_values)\n",
    "index = 0\n",
    "for i,j in enumerate(mean_values):\n",
    "    if j == max_value:\n",
    "        index = i\n",
    "\n",
    "alpha_chosen = alpha_values[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a classifier based on the alpha that i chose\n",
    "clf = linear_model.Lasso(alpha = alpha_chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=2.019999999999999, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_scaler,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_for_training = clf.predict(X_train_scaler)\n",
    "prediction_for_testing = clf.predict(X_test_scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2_score_for_scaler_training = r2_score(y_train,prediction_for_training)\n",
    "r2_score_for_scaler_testing = r2_score(y_test,prediction_for_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_used = []\n",
    "for i in range(0,len(clf.coef_)):\n",
    "    if clf.coef_[i] != 0:\n",
    "        features_used.append(features[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the alpha chosen is: 2.019999999999999\n",
      "the number of features used is: 7\n",
      "the features used in order to predict this dataset are: ['SEX', 'BMI', 'BP', 'S1', 'S3', 'S5', 'S6']\n",
      "the r squared for the training set is: 0.5210279848784138\n",
      "the r squared for the training set is: 0.45462092735500503\n"
     ]
    }
   ],
   "source": [
    "print(\"the alpha chosen is:\",alpha_chosen)\n",
    "print(\"the number of features used is:\",len(features_used))\n",
    "print(\"the features used in order to predict this dataset are:\",features_used)\n",
    "print(\"the r squared for the training set is:\",r2_score_for_scaler_training)\n",
    "print(\"the r squared for the training set is:\",r2_score_for_scaler_testing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 a) splitting the training set  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the data into training and testing but taking only 99 test size\n",
    "X_train_proper_set, X_calibration_set, y_train_proper_set, y_calibration = train_test_split(X_train, y_train, test_size=99, random_state=408)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 b) preprocessing into StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling the data based on the training set\n",
    "scaler = StandardScaler().fit(X_train_proper_set)\n",
    "X_train_scaler = scaler.transform(X_train_proper_set)\n",
    "X_calibration_scaler = scaler.transform(X_calibration_set)\n",
    "X_test_scaler = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=2.019999999999999, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "      normalize=False, positive=False, precompute=False, random_state=None,\n",
       "      selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train_scaler,y_train_proper_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11 c) non-conformity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first I have calculated the absolute value of the (y_true - y-calculated) where the y_calculated is using the calibration scaler\n",
    "#data set for predicting. the, I have sorted the data afterwards\n",
    "prediction_values = abs(y_calibration - clf.predict(X_calibration_scaler))\n",
    "prediction_values = np.sort(prediction_values)\n",
    "\n",
    "#for 5% and 20% significance, I have taken the value of the index 94 and the index 79 ( because its 99 - 5 and 99 - 20)\n",
    "value_for_5_percent = prediction_values[len(X_calibration_set) - 5]\n",
    "value_for_20_percent = prediction_values[len(X_calibration_set) - 20]\n",
    "\n",
    "#this is creating an empty numpy array for the 5% and 20% to be used later\n",
    "prediction_for_5 = np.empty(shape=(len(X_test_scaler),2))\n",
    "prediction_for_20 = np.empty(shape=(len(X_test_scaler),2))\n",
    "\n",
    "#in here, I am getting an interval of data for 5% and 20% \n",
    "for i in range(len(X_test_scaler)):\n",
    "    pre_5 = clf.predict(X_test_scaler)[i] - value_for_5_percent\n",
    "    post_5 = clf.predict(X_test_scaler)[i] + value_for_5_percent\n",
    "    pre_20 = clf.predict(X_test_scaler)[i] - value_for_20_percent\n",
    "    post_20 = clf.predict(X_test_scaler)[i] + value_for_20_percent\n",
    "    prediction_for_5[i] = [pre_5,post_5]\n",
    "    prediction_for_20[i] = [pre_20,post_20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length for 5% is: 219.41058852261847\n",
      "length for 20% is: 144.75706562014716\n"
     ]
    }
   ],
   "source": [
    "#basically, the length can be calculated using value*2 or just minimizing the post and pre of each significance\n",
    "print(\"length for 5% is:\",value_for_5_percent*2)\n",
    "print(\"length for 20% is:\",value_for_20_percent*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have used the test error rate initialized previously to calculate this\n",
    "error_5 = test_error_rate(y_test,prediction_for_5)\n",
    "error_20 = test_error_rate(y_test,prediction_for_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the test error rate for the 5% significance is: 0.06306306306306306\n",
      "the test error rate for the 20% significance is: 0.22522522522522523\n"
     ]
    }
   ],
   "source": [
    "print(\"the test error rate for the 5% significance is:\",error_5)\n",
    "print(\"the test error rate for the 20% significance is:\",error_20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# all values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all values has been giving in this jupyter notebook in details and in this section I will present all the values in a more clean and visible way"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) \n",
    "- training r squared: 0.36859375515801496\n",
    "- testing r squared : 0.3403312415954568\n",
    "- the number of features used is: 3\n",
    "- the features used: ('bmi','bp','s5')\n",
    "\n",
    "6)\n",
    "- training r squared: 0.5219263505249627\n",
    "- testing r squared: 0.4364337921284196\n",
    "- the number of features used is: 8\n",
    "- the features used:('sex', 'bmi', 'bp', 's1', 's2', 's3', 's5', 's6')\n",
    "\n",
    "8)\n",
    "- training r squared: 0.5253295326189974\n",
    "- testing r squared: 0.45579992198161157\n",
    "- the number of features used is: 7\n",
    "- the features used: ('sex', 'bmi', 'bp', 's1', 's3', 's5', 's6')\n",
    "\n",
    "10)\n",
    "- the alpha chosen is: 2.019999999999999\n",
    "- training r squared: 0.5210279848784138\n",
    "- testing r squared: 0.45462092735500503\n",
    "- the number of features used is: 7\n",
    "- the features used: ('SEX', 'BMI', 'BP', 'S1', 'S3', 'S5', 'S6')\n",
    "\n",
    "11)\n",
    "- length for 5% is: 219.41058852261847\n",
    "- length for 20% is: 144.75706562014716\n",
    "- the test error rate for the 5%: 0.06306306306306306\n",
    "- the test error rate for the 20%: 0.22522522522522523"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
